
\documentclass[11pt,letterpaper]{article}
\usepackage{naaclhlt2013}
\usepackage{times}
\usepackage{multirow}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{latexsym}
\usepackage{graphicx}
\graphicspath{{images/}}
\setlength\titlebox{6.5cm}

\title{TEA: Temporal Entity Annotator}

\author{Kevin Wacome\\
	    University of Massachusetts Lowell\\
	    1 University Ave\\
	    Lowell, MA 01854, USA\\
	    Kevin\_Wacome@student.uml.edu\\
	  \And
		Connor Cooper\\
	  	University of Massachusetts Lowell\\
	  	1 University Ave\\
	  	Lowell, MA 01854, USA\\
		Connor\_Cooper@student.uml.edu\\}

\begin{document}
\maketitle
\begin{abstract}
Temporal Entity Annotator (TEA) is a reimplementation of the system described by the SemEval-2015 Task-5 challenge winners. This tasks involves extracting temporal relation, temporal expressions, and event entities for the purpose of Question Answering. To achieve this, TEA is composed of a series of Support Vector Machine (SVM) classifiers, with one classifier for each extraction label. The creation of a replica system was not successful. The replica could not match the results of the original.
\end{abstract}

\section{Introduction}

The goal of this project was to implement a baseline system that performsed as well as the best competitors for the SemEval 2015 challenge titled QA TempEval, to provide a starting point for research into ways to improve performance of temporal relation extraction. The system annotates tokens within TE3Input files, which are a special class of TimeML file that lack full temporal annotation, but contain certain annotations such as document creation time. The tokens within these documents are annotated as either temporal expressions(TIMEX3) or events(EVENT). Temporal relations are then identified between EVENT/EVENT and EVENT/TIMEX3 pairs.\cite{Llorens:15}. Aside from entity detection, this task involved the annotation of relevant temporal information for use by a QA system. The QA system's role was to evaluate the quality of temporal entity annotations.


\section{Relevant Literature and Related Works}

TimeML is a markup specification that is used to represent temporal entities with the aims of providing a rich and informative representation to allow for accurate automatic recognition of temporal relations between entities by software systems \cite{Pustejovsky:03}. According to the TimeML specification, temporal entities are broken down into temporal expressions and events. Events are described as occurrences of situations and states and temporal expressions represent moments in time or durations. Temporal relations are described as the link between related entities that places them in a relative time frame to one another, such as preceding or occurring after.

Part of the challenge of this SemEval task is to create meaningful annotations that allow the QA system provided by the organizers to answer questions accurately. In the proceedings from SemEval 2015 \cite{Llorens:16}, a list of the systems that perform the best annotations was provided, some abstracts were also written describing the methods used to participate in this challenge. HLT-FBK was the system with the best general performance because it achieved on average the highest F-measure of all of the systems.

Two systems were ranked in the SemEval task out system is solving \cite{Llorens:16}. The HLT-FBK system, which our system is based on, ranked first, using a similar SVM based classification pipeline. The second place system, HITSZ-ICRC, utilized several other temporal annotation systems, and then fed them into a correction system. This correction system merged the output of the initial annotators.

HITSZ-ICRC annotations resulted in a reported F-measure of 0.12 by the QA system over the test corpus, opposed to the 0.37 F-measure from the HLT-FBK system \cite{Llorens:16}. Both systems were evaluated with the QA system distributed for the QA TempEval SemEval task. While neither system received a particularly high F-measure for the task, the HLT-FBK system clearly outperforms the HITSZ-ICRC system. For this reason, this version of TEA has been designed as a reimplementation of the HLT-FBK system. 

\section{Data and Tools}

TEA is tested, trained, and evaluated using the data distributed for the QA TempEval Task. A QA kit is also distributed for testing our annotations. Training data is composed of 25 documents with TE3Input files, as well as TBAQ cleaned files from the TimeBank and AQUAINT corpora. These provide an additional 256 documents to train over. The test data contains 8 blog entries, 10 news articles, and 10 Wikipedia articles.

Several external tools were leveraged to obtain feature and process data for the system. \textbf{NewsReader} is used for the majority of preprocessing. The tokenization, part of speech (PoS) tagging, named entity recognition, constituency tree, and semantic role labeling modules were utilized. \textbf{AddDiscoure} is used to extract temporal discourse connectives for several features \cite{Pitler:09}. \textbf{Scikit-learn} is used to implement our classifiers.

\subsection{Preprocessing}

TEA's preprocessing pipeline is implemented using NewsReader pipeline. From NewsReader, the IXA pipes modules are utilized to perform tokenization, part of speech tagging, named entity recognition, build constituency trees, and extract semantic role labels. This outputs an NAF format xml document, which is then parsed to obtain relevant information for each token. This information is then stored to be passed to the classifiers later.

\subsection{Temporal Expression Extraction}

The extraction and classification of temporal expressions (timex) is solved as a text chunking task. Timex expressions are classified as either DATE, TIME, or DURATION. Timexes can span multiple tokens, so IOB labellings are used, resulting in the following seven classes from the classifier: B\_DATE, I\_DATE, B\_TIME, I\_TIME, B\_DURATION, I\_DURATION, and O, for tokens that are not part of a timex. Timexes are classified using a single Suport Vector Machine (SVM) classifier with a polynomial kernal.

All tokens are considered as candidates for timexes. The features for this system for detecting Timexes include: token's text, lemma, part of speech, whether the token is a member of a named entity, the four tokens to the left and right of the token in question, word shape of the token, the grammar categories it belongs to according to a syntactic dependency tree parser.

\subsection{Event Extraction}

Event extraction is also taken as a text chunking task. Unlike the HLT-FBK system, which uses two classifiers to first identify events as either EVENT or O and then classify the events, TEA uses only one classifier to perform both tasks at once \cite{Mirza:15}. Events are classified as REPORTING, PERCEPTION, ASPECTUAL, ACTION, STATE, or OCCURRENCE. IOB labels are used to account for events which span multiple tokens, resulting in the following final labeling for the SVM classifier: B\_REPORTING, B\_PERCEPTION, B\_ASPECTUAL, B\_ACTION, B\_STATE, B\_OCCURRENCE, I\_REPORTING, I\_PERCEPTION, I\_ASPECTUAL, I\_ACTION, I\_STATE, I\_OCCURRENCE, or O for tokens that are not classified as events.

Every token that is not identified as a temporal entity is considered as a candidates for event classification. The features used to identify Events are: the token's text, lemma, part of speech, whether the token is part of a named entity, whether the token is the main verb of a sentence, whether the token is part of a temporal discourse connective, and the four tokens and labels to the left and right of the token in question, the grammar category the token belongs to, what the token's semantic role is and the tense of the token.

\subsection{Temporal Relation Extraction}

Temporal relation extraction is treated as a simple classification task across pairs of entities. The temporal links (TLINKs) are assigned one of 13 labels in accordance with the TimeML specification. However, in order to account for sparsity in the training data, only a subset of the original labels are used. Unused labels are mapped to other labels when encountered in training data, using the mappings shown below:


\begin{center}
	\begin{tabular}{ |c|c|c|c| } 
		\hline
		\textbf{Original TimeML Label} & \textbf{TEA Labeling Subset} \\
		\hline
		IDENTITY &  \\ 
		DURING & SIMULTANEOUS \\ 
		SIMULTANEOUS &  \\ 
		\hline
		IBEFORE & BEFORE \\
		BEFORE & \\
		\hline
		IAFTER & AFTER \\
		AFTER & \\
		\hline
		INCLUDES & IS\_INCLUDED \\
		IS\_INCLUDED & \\
		\hline
		BEGINS & BEGUN\_BY \\
		BEGUN\_BY & \\
		\hline
		ENDS & ENDED\_BY \\
		ENDED\_BY & \\
		\hline
		
	\end{tabular}
\end{center}

\vspace{5mm}

TLINKs are identified across TIMEX3/EVENT and EVENT/EVENT pairs. Only entities in the same sentence are considered as candidates for temporal relations, with a few notable exceptions. The document creation time (which servers as an anchor for all temporal expressions) is considered for relations with every event. Events containing the root verb of a sentence are also considered for pairing with events in the following sentence.

TLINKs are extracted using the following features: the labelings of each entity obtained from the previous two passes, whether the PoS tags of the entities are the same, how many sentences are between the entities (this is zero for most pairs, since most pairs considered are in the same sentence), how many entities occur between the two entities in the pair, whether an entity in the pairing is the document creation time, the tokens of any temporal discourse connectives that are between the entities, and the number of tokens between each entity and the temporal discourse connective (if one is present) and whether each token has the same attributes (ex: tense and polarity).Once all TLinks have been extracted, the annotations are written to a TimeML file in the systems output directory.

\section{Evaluation}

The data specified, the a QA tool was provided by semeval to evaluate the quality of our annotations. The system annotated 30 news, blog and wikipedia articles. The role of the QA tool is to use our annotations and try to answer predefined yes or no questions from our annotations.

\section{Results}

We can see by the tables that replicating the results of the system has been unsuccessful. Unfortunately none of the TLINK's that our replica annotates are recognized by the QA evaluation tool.

\section{Discussion}

It is unclear what specifically is the root cause of the systen's performance. Inspecting the output of the system shows that it can annotate entities as either EVENT or TIMEX3 and also generate TLINK pairings between EVENT/EVENT and EVENT/TIMEX3 pairings. It can be noted that the number of TLINK's annotated is quite low and may not generate enough temporal information for the QA system to work with.
The pipeline used by the newsreader project is limited to only news sources. We observed that the named entity recognizer used was not able to detect named entities for some blog files which prevented features dependent on this tool to not be able to be generated, such as constituency graphs.

Due to time constraints, not all features within the original system were implemented and it is unclear how large their impact would be on performance. Some interpretation had to be done for some of the method's that they used, which could be another potential source of error. Some of the features that seem like the most beneficial, that we were unable to implement, were: co-reference resolution using CorefGraph and timex normalization using TimeNorm and dependency based features. Ling and Weld note that dependency based features are very important because syntactic dependencies indicate temporal relations \cite{Ling:25}.

\begin{table}[b]{Table 1: TempEval QA Evaluations}
\centering

\begin{tabular}{c|cccc|cccc|cccc||c}

\multirow{2}{*}{} &
	\multicolumn{4}{c}{News} & 
	\multicolumn{4}{|c}{Wikipedia} & 
	\multicolumn{4}{|c||}{Blogs} & 
	\multicolumn{1}{c}{All Domains} \\
	
	& Cov & P & R & F1 
	& Cov & P & R & F1 
	& Cov & P & R & F1 
	& R\\
	\hline

	TEA & 
	0.00 & 0.00 & 0.00 & 0.00 & 
	0.01 & 1.00 & 0.01 & 0.02 & 
	0.02 & 0.00 & 0.00 & 0.00 & 
	0.01 \\

	HLT-FBK 1 &
	0.29 & 0.59 & 0.17 & 0.27 &
	0.29 & 0.55 & 0.16 & 0.25 &
	0.32 & 0.57 & 0.18 & 0.28 &
	0.17 \\
	
	HLT-FBK 2 &
	0.55 & 0.43 & 0.23 & 0.30 &
	0.50 & 0.52 & 0.26 & 0.35 &
	0.43 & 0.43 & 0.18 & 0.26 &
	0.23 \\
	
	HLT-FBK 3 &
	0.36 & 0.56 & 0.20 & 0.30 &
	0.29 & 0.58 & 0.17 & 0.26 &
	0.29 & 0.47 & 0.14 & 0.21 &
	0.17 \\
	
	HLT-FBK 4 &
	0.69 & 0.43 & 0.29 & 0.35 &
	0.58 & 0.62 & 0.36 & 0.46 &
	0.58 & 0.34 & 0.20 & 0.25 & 
	0.30 \\

\end{tabular}

\caption*{Coverage(Cov), Precision(P), Recall(R), F1-Score(F)}

\end{table}

More analysis needs to be done to pinpoint where our system is running into problems. We have the following possible scenarios: the missing features are the most vitally important, misinterpretation of the original paper's features for the features we implemented or some undiagnosed issues involving the formatting of acceptable output for the QA system. 


\section{Potential Improvements}

To improve our replica we must finish implementing all the features specified by the original paper to really gauge how much the missing features impacted our performance. 

Another potential improvement to the system is joint inference. By creating a bi-directional information flow between each of the classifiers as done by \cite{Singh:30}, we can reduce the errors that would normally accumulate through the pipeline. This will likely have significant benefit to the TIMEX3 and EVENT classifiers, which will in turn improve the quality of the TLINK classifier. This will allow us to make the most of the features we already have, rather than creating larger, more complex feature spaces.


\begin{thebibliography}{}

\bibitem[\protect\citename{Ling, Weld}2010]{Ling:25}
Xiao Ling and Daniel S. Weld.
\newblock 2010.
\newblock {\em  Temporal Information Extraction}.

\bibitem[\protect\citename{Llorens \bgroup et al.\egroup}2015]{Llorens:15}
Hector Llorens, Nate Chambers, Naushad UzZaman, Nasrin Mostafazadeh, James Allen and James Pustejovsky.
\newblock 2015.
\newblock {\em TempEval: Evaluating Temporal Information Understanding with QA}.

\bibitem[\protect\citename{{Llorens \bgroup et al.\egroup}}2015]{Llorens:16}
Hector Llorens, Nathanael Chambers, Naushad UzZaman, Nasrin Mostafazadeh, James Allen and James Pustejovsky.
\newblock 2015.
\newblock {\em SemEval-2015 Task 5: QA TEMPEVAL-Evaluating Temporal Information Understanding with Question Answering}.

\bibitem[\protect\citename{{Mirza, Minard}}2015]{Mirza:15}
Paramita Mirza and Anne-Lyse Minard.
\newblock 2015.
\newblock {\em HLT-FBK: a Complete Temporal Processing System for QA TempEval}.

\bibitem[\protect\citename{{Pitler, Emily}}2009]{Pitler:09}
Emily Pitler and Ani Nenkova.
\newblock 2009.
\newblock {\em Using Syntax to Disambiguate Explicit Discourse Connectives in Text.}.

\bibitem[\protect\citename{Pustejovsky \bgroup et al.\egroup}2003]{Pustejovsky:03}
James Pustejovsky, Jose Castano, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, Graham Katz and Dragomir Radev.
\newblock 2003.
\newblock {\em  TimeML: Robust specification of event and temporal expressions in text. New directions in question answering, 3, 28-34}.

\bibitem[\protect\citename{Singh \bgroup et al.\egroup}2013]
{Singh:30}
Singh, S., Riedel, S., Martin, B., Zheng, J., \& McCallum, A.
\newblock 2013.
\newblock {\em  Joint inference of entities, relations, and coreference. In Proceedings of the 2013 workshop on Automated knowledge base construction (pp. 1-6). ACM.}.

\end{thebibliography}
\end{document}
